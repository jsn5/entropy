<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Info Theory × ML Loss Explorer</title>
  <style>
    :root {
      /* Palette: Midnight & Cyan */
      --bg-app: #0f172a;
      --bg-sidebar: #020617;
      --bg-card: #1e293b;
      --bg-input: #334155;
      
      --text-primary: #f1f5f9;  /* Brighter white */
      --text-secondary: #cbd5e1; /* Lighter gray for better legibility */
      --text-accent: #38bdf8;   /* Cyan-400 */
      
      --border: #334155;
      
      --font-sans: 'Inter', system-ui, -apple-system, sans-serif;
      --font-mono: 'JetBrains Mono', 'Fira Code', monospace;
      
      --radius: 12px;
      --ease: cubic-bezier(0.2rder);
      padding: 32px 20px;
      display: flex;
      flex-direction: column;
      gap: 32px;
    }

    .brand {
      font-size: 18px;
      font-weight: 800;
      color: var(--text-primary);
      padding: 0 12px;
      letter-spacing: -0.02em;
    }
    
    .brand span { color: var(--text-accent); }

    .nav-menu {
      display: flex;
      flex-direction: column;
      gap: 6px;
    }

    .nav-item {
      padding: 12px 14px;
      border-radius: var(--radius);
      color: var(--text-secondary);
      font-size: 14px;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s var(--ease);
      border: 1px solid transparent;
    }

    .nav-item:hover {
      background-color: rgba(255,255,255,0.05);
      color: var(--text-primary);
    }

    .nav-item.active {
      background-color: rgba(56, 189, 248, 0.15);
      color: var(--text-accent);
      border-color: rgba(56, 189, 248, 0.2);
      font-weight: 600;
    }

    /* --- MAIN CONTENT AREA --- */
    .main-area {
      display: grid;
      grid-template-columns: minmax(0, 1.3fr) minmax(0, 0.9fr); /* More space for text */
      overflow: hidden;
    }

    @media (max-width: 900px) {
      .main-area { 
        grid-template-columns: 1fr; 
        overflow-y: auto;
        display: block;
      }
    }

    /* --- LEFT PANE: THEORY --- */
    .theory-pane {
      padding: 48px; /* More breathing room */
      overflow-y: auto;
      border-right: 1px solid var(--border);
    }

    .section-content { display: none; animation: fadeIn 0.4s var(--ease); }
    .section-content.active { display: block; }

    h1 { 
      font-size: 32px; 
      font-weight: 800; 
      margin: 0 0 24px 0; 
      color: var(--text-primary); 
      letter-spacing: -0.03em;
    }
    
    h2 { 
      font-size: 13px; 
      color: var(--text-accent); 
      text-transform: uppercase; 
      letter-spacing: 0.08em; 
      margin: 40px 0 16px 0; 
      font-weight: 700; 
      border-bottom: 1px solid rgba(56,189,248,0.2);
      padding-bottom: 8px;
      display: inline-block;
    }

    p { 
      color: var(--text-secondary); 
      margin-bottom: 24px; 
      max-width: 65ch; /* Optimal line length */
    }

    ul { 
      padding-left: 20px; 
      color: var(--text-secondary); 
      margin-bottom: 24px;
    }
    li { margin-bottom: 10px; }

    .badge {
      font-size: 11px; 
      padding: 4px 10px; 
      border-radius: 99px;
      background: rgba(148,163,184,0.1);
      border: 1px solid rgba(148,163,184,0.3); 
      color: var(--text-secondary);
      font-weight: 600;
      text-transform: uppercase; 
      letter-spacing: 0.05em; 
      display: inline-block; 
      margin-bottom: 16px;
    }
    
    /* IMPROVED FORMULA BOX */
    .equation-box {
      background: #020617;
      border: 1px solid var(--border);
      border-left: 4px solid var(--text-accent); /* Highlight strip */
      border-radius: 8px;
      padding: 24px;
      margin: 28px 0;
      font-family: var(--font-mono);
      font-size: 17px; /* Larger font */
      color: #fff;
      overflow-x: auto;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.3);
    }

    .equation-step {
      display: flex;
      margin-bottom: 12px;
      align-items: baseline;
    }
    .equation-step:last-child { margin-bottom: 0; }
    .eq-left { min-width: 140px; color: var(--text-secondary); font-size: 15px; }
    .eq-right { color: var(--text-accent); font-weight: 500; }

    /* IMPROVED INSIGHT CARD */
    .insight-card {
      background: linear-gradient(to right, rgba(56, 189, 248, 0.05), transparent);
      border: 1px solid rgba(56, 189, 248, 0.2);
      border-radius: var(--radius);
      padding: 20px 24px;
      margin: 28px 0;
      font-size: 15px;
      color: var(--text-secondary);
      position: relative;
    }
    .insight-card strong { color: #fff; font-weight: 600; }
    
    .chips { display: flex; gap: 10px; flex-wrap: wrap; margin: 20px 0; }
    .chip { 
      font-size: 12px; 
      padding: 6px 12px; 
      background: var(--bg-input); 
      border-radius: 6px; 
      color: #fff; 
      font-weight: 500;
      border: 1px solid rgba(255,255,255,0.05);
    }

    /* --- RIGHT PANE: LAB --- */
    .lab-pane {
      background-color: #0b1120;
      padding: 40px;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 32px;
      border-left: 1px solid #000;
    }

    .lab-group { display: none; }
    .lab-group.active { display: block; animation: fadeIn 0.4s var(--ease); }

    .lab-card {
      background-color: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 28px;
      box-shadow: 0 20px 40px -10px rgba(0,0,0,0.6);
    }

    .lab-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 28px;
      padding-bottom: 16px;
      border-bottom: 1px solid var(--border);
    }
    .lab-title { font-weight: 700; font-size: 16px; color: #fff; }
    
    /* CONTROLS */
    .control-group { margin-bottom: 24px; }
    .control-label { 
      display: flex; 
      justify-content: space-between; 
      font-size: 14px; 
      color: var(--text-secondary); 
      margin-bottom: 12px;
      font-weight: 500;
    }
    .val-display { 
      font-family: var(--font-mono); 
      color: var(--text-accent); 
      font-size: 14px; 
      background: rgba(0,0,0,0.3); 
      padding: 2px 8px; 
      border-radius: 6px; 
    }

    input[type=range] {
      -webkit-appearance: none; width: 100%; background: transparent;
    }
    input[type=range]::-webkit-slider-thumb {
      -webkit-appearance: none; height: 20px; width: 20px; border-radius: 50%;
      background: var(--text-accent); cursor: pointer; margin-top: -8px;
      box-shadow: 0 0 15px rgba(56,189,248,0.5);
      border: 2px solid #fff;
    }
    input[type=range]::-webkit-slider-runnable-track {
      width: 100%; height: 4px; cursor: pointer; background: var(--bg-input); border-radius: 2px;
    }

    /* RESULTS */
    .result-grid {
      display: grid; gap: 12px; background: #0f172a;
      padding: 20px; border-radius: var(--radius); border: 1px solid var(--border);
    }
    .result-item { display: flex; justify-content: space-between; align-items: center; font-size: 14px; color: var(--text-secondary); }
    .result-val { font-family: var(--font-mono); font-size: 15px; color: var(--text-accent); font-weight: 600; }
    
    .hint { font-size: 13px; color: var(--text-secondary); opacity: 0.8; margin-top: 16px; line-height: 1.5; font-style: italic; }

    /* QUIZ BOX */
    .quiz-box {
      margin-top: 24px;
      padding: 16px;
      background: rgba(255,255,255,0.03);
      border-radius: 8px;
      border: 1px dashed var(--border);
      cursor: pointer;
      transition: all 0.2s ease;
    }
    .quiz-box:hover { background: rgba(255,255,255,0.05); border-color: var(--text-secondary); }
    .quiz-box.open { border-color: var(--text-accent); background: rgba(56, 189, 248, 0.05); }
    .quiz-question { font-size: 14px; font-weight: 700; color: #fff; display: flex; align-items: center; gap: 10px; }
    .quiz-answer { 
      font-size: 14px; color: var(--text-primary); margin-top: 12px; display: none; line-height: 1.6; 
      padding-top: 12px; border-top: 1px solid rgba(255,255,255,0.1);
    }
    .quiz-box.open .quiz-answer { display: block; }

    /* TOGGLE BUTTONS */
    .toggle-row { display: flex; background: var(--bg-sidebar); padding: 4px; border-radius: 8px; border: 1px solid var(--border); }
    .toggle-btn {
      flex: 1; border: none; background: transparent; color: var(--text-secondary);
      padding: 10px; font-size: 13px; cursor: pointer; border-radius: 6px; font-weight: 600;
    }
    .toggle-btn.active { background: var(--bg-input); color: #fff; }

    @keyframes fadeIn { from { opacity: 0; transform: translateY(8px); } to { opacity: 1; transform: translateY(0); } }
  </style>
</head>
<body>

  <div class="app-container">
    
    <nav class="sidebar">
      <div class="brand">
        Info Theory <span>×</span> ML Loss
      </div>
      <div class="nav-menu">
        <div class="nav-item active" data-tab="overview" onclick="switchTab('overview')">Overview</div>
        <div class="nav-item" data-tab="entropy" onclick="switchTab('entropy')">Entropy</div>
        <div class="nav-item" data-tab="ce" onclick="switchTab('ce')">Cross-Entropy</div>
        <div class="nav-item" data-tab="bce" onclick="switchTab('bce')">Binary CE & Sigmoid</div>
        <div class="nav-item" data-tab="kl" onclick="switchTab('kl')">KL Divergence</div>
        <div class="nav-item" data-tab="playground" onclick="switchTab('playground')">Playground</div>
      </div>
    </nav>

    <main class="main-area">
      
      <div class="theory-pane">
        
        <div id="content-overview" class="section-content active">
          <span class="badge">Foundations</span>
          <h1>The Atomic Unit</h1>
          
          <h2>Step 1: Surprise I(x)</h2>
          <p>
            Before we talk about Entropy, we must define the <strong>"Surprise"</strong> (or self-information) of a single event $x$.
            If an event is rare, it is surprising. If it is certain, there is no surprise.
          </p>
          <div class="equation-box">
             I(x) = -log₂ P(x)
          </div>
          <div class="insight-card">
            <strong>Key Examples:</strong>
            <ul style="margin:12px 0 0 0; padding-left:16px;">
              <li><strong>P(x) = 1.0 (Certain):</strong> log(1) = 0. Zero bits of surprise.</li>
              <li><strong>P(x) = 0.5 (Coin Flip):</strong> -log₂(0.5) = 1. One bit of surprise.</li>
              <li><strong>P(x) ≈ 0 (Rare):</strong> Large positive surprise.</li>
            </ul>
          </div>

          <h2>Step 2: Entropy H(P)</h2>
          <p>
            Entropy is simply the <strong>Expected Value</strong> (average) of the surprise for all possible outcomes.
            It's the weighted sum of the surprise of every event.
          </p>
          <div class="equation-box">
            <div class="equation-step">
              <div class="eq-left">H(P)</div>
              <div class="eq-right">= E [ I(x) ]</div>
            </div>
            <div class="equation-step">
              <div class="eq-left"></div>
              <div class="eq-right">= Σ P(x) · I(x)</div>
            </div>
            <div class="equation-step" style="border-top:1px solid rgba(255,255,255,0.1); margin-top:8px; padding-top:8px;">
              <div class="eq-left">Formula:</div>
              <div class="eq-right">- Σ P(x) log₂ P(x)</div>
            </div>
          </div>
          <p>
            This formula tells us the "average amount of information" (in bits) we get from sampling this distribution.
          </p>

          <h2>Step 3: From Entropy to Loss</h2>
          <p>
            In Machine Learning, we don't know the true distribution P. We approximate it with a model Q.
            Our loss function (Cross-Entropy) measures the <strong>average surprise</strong> of the true data P, when evaluated using our model Q.
          </p>
          <div class="chips">
            <span class="chip">I(x) = Unit of info</span>
            <span class="chip">H(P) = Average info</span>
            <span class="chip">CE = Average info under Model Q</span>
          </div>
        </div>

        <div id="content-entropy" class="section-content">
          <span class="badge">Uncertainty of Nature</span>
          <h1>Entropy H(P)</h1>
          
          <h2>Definition</h2>
          <p>Entropy is the <strong>average surprise</strong> when outcomes are drawn from a distribution P.</p>
          <div class="equation-box">H(P) = − Σ P(x) log P(x)</div>

          <h2>Intuition: Fair vs. Unfair Dice</h2>
          <p>Imagine two different 6-sided dice:</p>
          <ul>
            <li><strong>Fair Die:</strong> Every side has probability 1/6. You have <i>no idea</i> what will happen next. The uncertainty is maximized. <br><span style="color:var(--text-accent); font-weight:600;">Entropy is High.</span></li>
            <li><strong>Loaded (Unfair) Die:</strong> One side comes up 90% of the time. You are fairly certain what will happen. <br><span style="color:var(--text-accent); font-weight:600;">Entropy is Low.</span></li>
          </ul>
          <div class="insight-card">
            Entropy measures <strong>unpredictability</strong>. If a system is rigged (deterministic), entropy drops towards zero.
          </div>
        </div>

        <div id="content-ce" class="section-content">
          <span class="badge">Multi-Class (Softmax)</span>
          <h1>Cross-Entropy Loss</h1>
          
          <h2>Definition</h2>
          <p>Cross-entropy H(P, Q) is the average surprise if the world follows P but you <strong>use Q to measure probabilities</strong>.</p>
          <div class="equation-box">H(P, Q) = − Σ P(x) log Q(x)</div>

          <h2>In classification with one-hot labels</h2>
          <p>For a single sample, let the correct class be <code>k</code>. Then:</p>
          <div class="equation-box">P(k) = 1, &nbsp; P(j≠k) = 0</div>
          <p>Cross-entropy simplifies to:</p>
          <div class="equation-box">H(P, Q) = −log Q(k)</div>
          <div class="insight-card">
            Because P is 100% certain on the label, H(P)=0. Thus Cross-Entropy becomes purely KL Divergence (the error).
          </div>
        </div>

        <div id="content-bce" class="section-content">
          <span class="badge">Binary / Multi-Label</span>
          <h1>Binary Cross-Entropy & Sigmoid</h1>
          
          <h2>Sigmoid as probability</h2>
          <div class="equation-box">σ(z) = 1 / (1 + e<sup>−z</sup>)</div>

          <h2>Binary cross-entropy (per label)</h2>
          <p>For a single yes/no label with true value y ∈ {0,1} and predicted probability p:</p>
          <div class="equation-box">L = −[ y log(p) + (1−y) log(1−p) ]</div>
          <div class="insight-card">
            This effectively runs two separate loss checks: "Did you assign high probability if True?" and "Did you assign low probability if False?"
          </div>
        </div>

        <div id="content-kl" class="section-content">
          <span class="badge">Extra Surprise</span>
          <h1>KL Divergence</h1>
          
          <h2>Definition</h2>
          <p>KL measures how many <strong>extra bits of surprise</strong> you suffer because you use the wrong model Q for a world that follows P.</p>

          <h2>Derivation from H(P,Q) - H(P)</h2>
          <p>We know that Cross-Entropy is Entropy plus KL. Let's solve for KL:</p>
          <div class="equation-box">
            <div class="equation-step">
              <div class="eq-left">KL(P‖Q) =</div>
              <div class="eq-right">H(P, Q) − H(P)</div>
            </div>
            <div class="equation-step">
              <div class="eq-left">=</div>
              <div class="eq-right">−Σ P(x) log Q(x) − [−Σ P(x) log P(x)]</div>
            </div>
            <div class="equation-step">
              <div class="eq-left">=</div>
              <div class="eq-right">Σ P(x) log P(x) − Σ P(x) log Q(x)</div>
            </div>
            <div class="equation-step">
              <div class="eq-left">=</div>
              <div class="eq-right">Σ P(x) [ log P(x) − log Q(x) ]</div>
            </div>
            <div class="equation-step" style="margin-top:12px; border-top:1px solid rgba(255,255,255,0.1); padding-top:12px;">
              <div class="eq-left">Final Ratio:</div>
              <div class="eq-right">Σ P(x) log( P(x) / Q(x) )</div>
            </div>
          </div>
          <p>The "ratio" inside the log explains why it's a divergence. If P(x) = Q(x), the ratio is 1, and log(1) is 0.</p>
        </div>

        <div id="content-playground" class="section-content">
          <span class="badge">Interactive</span>
          <h1>Playground</h1>
          <p>Use the panels on the right to interact with the concepts.</p>
        </div>

      </div>

      <div class="lab-pane">
        
        <div id="lab-overview" class="lab-group active">
           <div class="lab-card">
             <div class="lab-header">
               <div class="lab-title">Cheat Sheet</div>
               <span class="badge" style="margin:0">At a Glance</span>
             </div>
             <div class="result-grid">
               <div class="result-item"><span>Surprise I(x)</span> <span style="color:#fff">-log P(x)</span></div>
               <div class="result-item"><span>Entropy H(P)</span> <span style="color:#fff">Σ P(x)·I(x)</span></div>
               <div class="result-item"><span>Cross-Ent H(P,Q)</span> <span style="color:#fff">Σ P(x)·I_model(x)</span></div>
             </div>
             <div class="hint">Select a tab from the sidebar to open a specific calculator.</div>
           </div>
        </div>
        
        <div id="lab-playground" class="lab-group">
          <div class="lab-card">
            <div class="lab-header">
              <div class="lab-title">Comparison Lab</div>
              <span class="badge" style="margin:0">CE vs BCE</span>
            </div>
            <div class="control-group">
              <div class="control-label"><span>p(correct)</span> <span class="val-display" id="disp-combo-p">0.20</span></div>
              <input type="range" min="1" max="99" value="20" id="input-combo-p">
            </div>
            <div class="result-grid">
              <div class="result-item"><span>Softmax CE</span> <span class="result-val" id="res-combo-ce">1.609</span></div>
              <div class="result-item"><span>BCE (y=1)</span> <span class="result-val" id="res-combo-bce1">1.609</span></div>
            </div>
            <div class="quiz-box" onclick="toggleQuiz(this)">
              <div class="quiz-question"><span>?</span> Comparison Challenge</div>
              <div class="quiz-answer">
                Softmax CE and BCE (where y=1) produce the exact same loss curve wrt probability. The difference is only in how that probability is normalized (against all classes vs against just 0/1).
              </div>
            </div>
          </div>
        </div>

        <div id="lab-entropy" class="lab-group">
          <div class="lab-card">
            <div class="lab-header">
              <div class="lab-title">Entropy: The Die Roll</div>
              <span class="badge" style="margin:0">Dice Toy</span>
            </div>
            <div class="control-group">
              <div class="control-label">
                <span>Sides (N)</span>
                <span class="val-display" id="disp-ent-n">6</span>
              </div>
              <input type="range" min="2" max="10" value="6" id="input-ent-n">
            </div>

            <div class="control-group">
              <div class="control-label"><span>Die Fairness</span></div>
              <div class="toggle-row">
                <button class="toggle-btn active" id="btn-fair" onclick="setFairness(true)">Fair (Uniform)</button>
                <button class="toggle-btn" id="btn-unfair" onclick="setFairness(false)">Unfair (Loaded)</button>
              </div>
            </div>

            <div class="result-grid" style="margin-top:12px">
              <div class="result-item">
                <span>Entropy (bits)</span>
                <span class="result-val" id="res-ent-val">2.585</span>
              </div>
              <div class="result-item" id="row-prob-dist">
                <span style="font-size:13px; opacity:0.6">P = [1/6, 1/6, 1/6, ...]</span>
              </div>
            </div>

            <div class="quiz-box" onclick="toggleQuiz(this)">
              <div class="quiz-question"><span>?</span> Think: If the die becomes unfair, does entropy go up or down?</div>
              <div class="quiz-answer">
                It goes <strong>DOWN</strong>. <br>Entropy measures uncertainty. If the die is loaded (unfair), you can predict the outcome more easily, so the surprise (entropy) decreases.
              </div>
            </div>
          </div>
        </div>

        <div id="lab-ce" class="lab-group">
          <div class="lab-card">
            <div class="lab-header">
              <div class="lab-title">Cross-Entropy Playground</div>
              <span class="badge" style="margin:0">Softmax Style</span>
            </div>
            <div class="control-group">
              <div class="control-label">
                <span>p(correct)</span>
                <span class="val-display" id="disp-ce-p">0.70</span>
              </div>
              <input type="range" min="1" max="99" value="70" id="input-ce-p">
            </div>
            <div class="result-grid" style="margin-top:12px">
              <div class="result-item"><span>Loss = −ln(p)</span> <span class="result-val" id="res-ce-loss">0.357</span></div>
            </div>
            <div class="quiz-box" onclick="toggleQuiz(this)">
              <div class="quiz-question"><span>?</span> Why does loss approach infinity as p → 0?</div>
              <div class="quiz-answer">
                Because you are saying an event is "impossible" (p=0), but it actually happened (y=1). The surprise is infinite.
              </div>
            </div>
          </div>
        </div>

        <div id="lab-bce" class="lab-group">
          <div class="lab-card">
            <div class="lab-header">
              <div class="lab-title">Binary CE & Sigmoid</div>
              <span class="badge" style="margin:0">Bernoulli</span>
            </div>
            <div class="control-group">
              <div class="control-label"><span>Logit z</span> <span class="val-display" id="disp-bce-z">2.00</span></div>
              <input type="range" min="-600" max="600" value="200" id="input-bce-z">
            </div>
            <div class="control-group">
              <div class="toggle-row">
                <button class="toggle-btn active" id="btn-y-1" onclick="setBceY(1)">y = 1</button>
                <button class="toggle-btn" id="btn-y-0" onclick="setBceY(0)">y = 0</button>
              </div>
            </div>
            <div class="result-grid">
              <div class="result-item"><span>Sigmoid σ(z)</span><span class="result-val" id="res-bce-p">0.88</span></div>
              <div class="result-item"><span>BCE loss</span><span class="result-val" id="res-bce-loss">0.129</span></div>
            </div>
          </div>
        </div>

        <div id="lab-kl" class="lab-group">
          <div class="lab-card">
            <div class="lab-header">
              <div class="lab-title">KL Calculator</div>
              <span class="badge" style="margin:0">Numeric</span>
            </div>
            <div class="control-group">
              <div class="control-label"><span>True p (P[1])</span> <span class="val-display" id="disp-kl-p">0.50</span></div>
              <input type="range" min="1" max="99" value="50" id="input-kl-p">
            </div>
            <div class="control-group">
              <div class="control-label"><span>Model q (Q[1])</span> <span class="val-display" id="disp-kl-q">0.90</span></div>
              <input type="range" min="1" max="99" value="90" id="input-kl-q">
            </div>
            <div class="result-grid">
              <div class="result-item"><span>Entropy H(P)</span> <span class="result-val" id="res-kl-h">0.693</span></div>
              <div class="result-item"><span>Cross-Ent H(P,Q)</span> <span class="result-val" id="res-kl-ce">1.228</span></div>
              <div class="result-item"><span>KL(P‖Q)</span> <span class="result-val" id="res-kl-val">0.535</span></div>
            </div>
            <div class="quiz-box" onclick="toggleQuiz(this)">
              <div class="quiz-question"><span>?</span> When is KL Divergence exactly zero?</div>
              <div class="quiz-answer">
                Only when P = Q exactly. If your model's beliefs perfectly match reality, there is no "divergence" or extra surprise.
              </div>
            </div>
          </div>
        </div>

      </div>
    </main>
  </div>

<script>
  /* --- UI LOGIC --- */
  function switchTab(id) {
    document.querySelectorAll('.nav-item').forEach(el => el.classList.remove('active'));
    const activeItem = document.querySelector(`.nav-item[data-tab="${id}"]`);
    if(activeItem) activeItem.classList.add('active');

    document.querySelectorAll('.section-content').forEach(el => el.classList.remove('active'));
    const contentId = 'content-' + id;
    const contentEl = document.getElementById(contentId) || document.getElementById('content-overview');
    contentEl.classList.add('active');

    document.querySelectorAll('.lab-group').forEach(el => el.classList.remove('active'));
    const labId = 'lab-' + id;
    const labEl = document.getElementById(labId) || document.getElementById('lab-overview');
    labEl.classList.add('active');
  }

  function toggleQuiz(el) {
    el.classList.toggle('open');
  }

  /* --- MATH LOGIC --- */
  const safeLog = (x) => Math.log(Math.max(x, 1e-12));
  const sigmoid = (z) => {
      if (z >= 0) return 1 / (1 + Math.exp(-z));
      else return Math.exp(z) / (1 + Math.exp(z));
  };

  /* 1. ENTROPY LOGIC (UPDATED) */
  const inpEntN = document.getElementById('input-ent-n');
  let isFair = true;

  function updateEntropy() {
    const N = parseInt(inpEntN.value);
    document.getElementById('disp-ent-n').innerText = "N = " + N;
    
    let H = 0;
    let desc = "";

    if(isFair) {
      // Uniform: p = 1/N
      H = Math.log2(N);
      desc = "P = uniform";
    } else {
      // Unfair: Skewed distribution (simulated)
      // Assume one side has 90% probability, others split 10%
      const pMax = 0.9;
      const pRest = 0.1 / (N - 1);
      
      // H = - [ pMax*log(pMax) + (N-1)*pRest*log(pRest) ]
      H = - ( pMax * Math.log2(pMax) + (N-1) * pRest * Math.log2(pRest) );
      desc = "P = [0.9, ...]";
    }

    document.getElementById('res-ent-val').innerText = H.toFixed(3);
    document.getElementById('row-prob-dist').innerHTML = `<span style="font-size:11px; opacity:0.6">${desc}</span>`;
  }

  function setFairness(fair) {
    isFair = fair;
    document.getElementById('btn-fair').classList.toggle('active', fair);
    document.getElementById('btn-unfair').classList.toggle('active', !fair);
    updateEntropy();
  }

  if(inpEntN) inpEntN.addEventListener('input', updateEntropy);


  /* 2. CROSS ENTROPY */
  const inpCeP = document.getElementById('input-ce-p');
  if(inpCeP) inpCeP.addEventListener('input', (e) => {
    const p = parseInt(e.target.value) / 100;
    document.getElementById('disp-ce-p').innerText = p.toFixed(2);
    document.getElementById('res-ce-loss').innerText = (-Math.log(p)).toFixed(3);
  });

  /* 3. BCE */
  let bceY = 1;
  const inpBceZ = document.getElementById('input-bce-z');
  
  function updateBCE() {
    const z = parseInt(inpBceZ.value) / 100;
    const p = sigmoid(z);
    
    document.getElementById('disp-bce-z').innerText = z.toFixed(2);
    document.getElementById('res-bce-p').innerText = p.toFixed(4); 
    
    let loss;
    if (bceY === 1) loss = -Math.log(p);
    else loss = -Math.log(1 - p);
    
    document.getElementById('res-bce-loss').innerText = loss.toFixed(4);
  }

  function setBceY(val) {
    bceY = val;
    document.getElementById('btn-y-0').classList.toggle('active', val === 0);
    document.getElementById('btn-y-1').classList.toggle('active', val === 1);
    updateBCE();
  }
  if(inpBceZ) inpBceZ.addEventListener('input', updateBCE);

  /* 4. KL DIVERGENCE */
  const inpKlP = document.getElementById('input-kl-p');
  const inpKlQ = document.getElementById('input-kl-q');

  function updateKL() {
    const p = parseInt(inpKlP.value) / 100;
    const q = parseInt(inpKlQ.value) / 100;
    
    document.getElementById('disp-kl-p').innerText = p.toFixed(2);
    document.getElementById('disp-kl-q').innerText = q.toFixed(2);

    const p0 = 1 - p;
    const q0 = 1 - q;

    const h_p = -(p * safeLog(p) + p0 * safeLog(p0));
    const ce_pq = -(p * safeLog(q) + p0 * safeLog(q0));
    const kl = ce_pq - h_p;

    document.getElementById('res-kl-h').innerText = h_p.toFixed(3);
    document.getElementById('res-kl-ce').innerText = ce_pq.toFixed(3);
    document.getElementById('res-kl-val').innerText = kl.toFixed(3);
  }
  if(inpKlP) { inpKlP.addEventListener('input', updateKL); inpKlQ.addEventListener('input', updateKL); }

  /* 5. COMBO */
  const inpComboP = document.getElementById('input-combo-p');
  if(inpComboP) inpComboP.addEventListener('input', (e) => {
    const p = parseInt(e.target.value) / 100;
    document.getElementById('disp-combo-p').innerText = p.toFixed(2);
    const valP = Math.max(p, 1e-12);
    document.getElementById('res-combo-ce').innerText = (-Math.log(valP)).toFixed(3);
    document.getElementById('res-combo-bce1').innerText = (-Math.log(valP)).toFixed(3);
  });

  // Init
  updateEntropy();
  updateBCE();
  updateKL();

</script>
</body>
</html>
